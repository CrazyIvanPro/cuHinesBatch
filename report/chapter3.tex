\chapterimage{head3} % Chapter heading image

\chapter{Experimental Results}

Here is the Makefile for this project:

\begin{lstlisting}[title = {Makefile}]
    CC		   = g++
NVCC       = nvcc
LD_LIBRARY_PATH= /usr/local/cuda/lib64
CUDA_LIB   = -L /usr/local/cuda/lib64/ -lcuda -lcudart
 -lcusparse -lcusolver 
ARCH_CUDA  = -arch=sm_30
NVCC_FLAGS = --ptxas-options=-v -Xcompiler -fopenmp -O3 
-std=c++11  -D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES  
GCC_FLAGS  = -fopenmp -std=c++11 -Wall -pedantic  


all: clean serial parallel remove

serial: memm.o cuThomasVBatch.o serial.cc
    $(CC)   $(GCC_FLAGS) -o serial serial.cc $(CUDA_LIB) 
    memm.o cuThomasVBatch.o	

parallel: memm.o cuThomasVBatch.o parallel.cc
    $(CC)   $(GCC_FLAGS) -o parallel parallel.cc $(CUDA_LIB) 
    memm.o cuThomasVBatch.o	

memm.o: memm.cu

	$(NVCC) -c  $(NVCC_FLAGS) $(ARCH_CUDA) memm.cu

cuThomasVBatch.o: cuThomasVBatch.cu 
    $(NVCC) -c  $(NVCC_FLAGS) $(ARCH_CUDA) 
    cuThomasVBatch.cu	 

clean:
	rm -rf *.o serial parallel

remove:
	rm -rf *.o
\end{lstlisting}

\vspace{5ex}
Here is the experimental results:

\begin{table}[htbp]
	\caption{Compare the metrics of different implementations (Case 8)}
	\centering
	\begin{tabular}[width=1.0\linewidth]{lllllll}
		\toprule
		\quad Method & Case 7 & Case 8 & Case 9 & Case 10 & Case 11 & Case 12\\
    \midrule
    Serial            & 1.832603e-03 & 4.852763e-03 & 1.556245e-2  & 2.745925e-2  & 1.34865e-1   & 1.624341e-1   \\
    OpenMP            & 6.644011e-02 & 2.541431e-03 & 3.947942e-2  & 2.346893e-2  & 5.79814e-1   & 3.565425e-1   \\
    cuHinesBatch      & 8.718967e-03 & 2.536453e-03 & 1.746943e-2  & 1.914897e-2  & 3.31285e-2   & 4.681494e-2   \\
    \bottomrule
	\end{tabular}
	\label{tab:table1}
\end{table}

\vspace{1ex}

From the results above, we could find out that the speedup > 1 for Multi-CPU and GPU implemenations both in large cases.
On the consideration of the parallel overhead, when the numbers $N$ rises, the paralleled version have better performance compared to the serial one.


\vspace{10ex}

Besides, we also tested the Heterogeneous Parallelization, but the performance is not satisfying.

